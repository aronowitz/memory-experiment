form
if(identical(form, 'default')){
form0 <- 'y ~ treat * time + (1|'
form1 <- ifelse(ncol(data) > 3, 'class/id', 'id')
form <- paste0(form0, form1, ')')
}
# makeMod
makeMod <- function(data, fixed, rand, sigma = 1, form = 'default'){
cols <- c('id', 'treat', 'time')
colnames(data) <- tolower(colnames(data))
stopifnot(all(cols %in% colnames(data)))
if(identical(form, 'default')){
form0 <- 'y ~ treat * time + (1|'
form1 <- ifelse(ncol(data) > 3, 'class/id', 'id')
form <- paste0(form0, form1, ')')
}
form <- as.formula(form)
out <- simr::makeLmer(formula = form, fixef = fixed,
VarCorr = rand, sigma = sigma,
data = data)
return(out)
}
rmall()
source('~/R/simr/powerFunctions.R')
out1 = makeCovs(10, 3, 2, 5)
excoefs()
m1 = makeMod(out1, fixed, rand, 2)
m1
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
m1 = makeMod(out1, fixed, rand, 1)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
out1 = makeCovs(10, 3, 2)
out1
m1 = makeMod(out1, fixed, rand[1])
m1
# makeMod
makeMod <- function(data, fixed, rand, sigma = 2, form = 'default'){
cols <- c('id', 'treat', 'time')
colnames(data) <- tolower(colnames(data))
stopifnot(all(cols %in% colnames(data)))
if(identical(form, 'default')){
form0 <- 'y ~ treat * time + (1|'
form1 <- ifelse(ncol(data) > 3, 'class/id', 'id')
form <- paste0(form0, form1, ')')
}
form <- as.formula(form)
out <- simr::makeLmer(formula = form, fixef = fixed,
VarCorr = rand, sigma = sigma,
data = data)
return(out)
}
m1
m1
m1 = makeMod(out1, fixed, rand[1])
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
m1
out1 = makeCovs(20, 3, 2)
out1
m1 = makeMod(out1, fixed, rand[1])
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
out1
out1 = makeCovs(40, 3, 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
params(4)
fixed = params(4)
# makeCovs: create data frame of covariates
makeCovs <- function(n, time, treat = 3, classes = NULL){
stopifnot(length(n) == 1); stopifnot(is.numeric(n))
stopifnot(length(time) == 1); stopifnot(is.numeric(time))
if(length(treat) == 1 & is.numeric(treat)){treat <- LETTERS[1:treat]}
stopifnot(!is.numeric(treat))
k <- n/length(treat)
while(!identical(k, round(k))){
n <- n + 1
k <- n/length(treat)
}
id <- factor(1:n)
time <- factor(1:time)
id2 <- rep(id, length(time))
time2 <- rep(time, each = length(id))
treat2 <- rep(rep(treat, each = k), length(time))
covs <- data.frame(id = id2, treat = treat2, time = time2)
if(!is.null(classes)){
if(length(classes) == 1 & is.numeric(classes)){
classes <- letters[1:classes]
}
if(!is.numeric(classes)){
kk <- length(classes)
classes <- rep(classes, each = nrow(covs))
covs <- data.frame(id = rep(id2, kk), class = classes,
treat = rep(treat2, kk),
time = rep(time2, kk))
covs <- covs[order(covs$time), ]
rownames(covs) <- 1:nrow(covs)
}
}
covs
}
out1 = makeCovs(20, 4, 3)
out1
m1 = makeMod(out1, fixed, list(.5), 2)
head(out1)
fixe
fixed
levels(out1$treat)
names(fixed) = NULL
m1 = makeMod(out1, fixed, list(.5), 2)
m1
# makeMod
makeMod <- function(data, fixed, rand, sigma = 2, form = 'default'){
cols <- c('id', 'treat', 'time')
colnames(data) <- tolower(colnames(data))
stopifnot(all(cols %in% colnames(data)))
if(identical(form, 'default')){
form0 <- 'y ~ treat * time + (1|'
form1 <- ifelse(ncol(data) > 3, 'class/id', 'id')
form <- paste0(form0, form1, ')')
}
form <- as.formula(form)
names(fixed) <- NULL; names(rand) <- NULL
out <- simr::makeLmer(formula = form, fixef = fixed,
VarCorr = rand, sigma = sigma,
data = data)
return(out)
}
fixed = params(4)
m1 = makeMod(out1, fixed, list(.5), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
out1
out1 = makeCovs(10, 3, 2, 5)
excoefs()
fixed
fixed2 = fixed
fixed2[1] = 0
fixed2
m1 = makeMod(out1, fixed, rand, 2)
m2 = makeMod(out1, fixed2, rand, 2)
set.seed(1)
sim1 = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim1
set.seed(1)
sim2 = powerSim(m2, nsim = 100, test = fcompare(y ~ time))
sim2
fixed
fixed[2] = .5
rmall()
source('~/R/simr/powerFunctions.R')
params(T)
m1 = makeMod(data, fixed, rand, 2)
set.seed91
set.seed(1)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
fixed <- params(4)
out1 <- makeCovs(100, 4)
sim
m1 = makeMod(out1, fixed, list(.5), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
fixed <- params(4)
out1 <- makeCovs(100, 4, classes = 4)
m1 = makeMod(out1, fixed, list(.5, .1), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
out1 <- makeCovs(30, 4, classes = 4)
m1 = makeMod(out1, fixed, list(.5, .1), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
fixed
out1
subset(out1, class == 'A')
head(out1)
subset(out1, class == 'a')
k = subset(out1, class == 'a')
count(k$time)
fixed
fixed = rep(.2, 12)
out1 <- makeCovs(30, 4, classes = 4)
m1 = makeMod(out1, fixed, list(.5, .1), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
fixed = rep(.4, 12)
m1 = makeMod(out1, fixed, list(.5, .1), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
fixed <- params(4)
out1 <- makeCovs(30, 4, classes = 4)
m1 = makeMod(out1, fixed, list(.5, .1), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
sim
out1
fixed
fixed = rep(.4, 12)
m1 = makeMod(out1, fixed, list(.5, .1), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
out1 <- makeCovs(50, 4, classes = 4)
m1 = makeMod(out1, fixed, list(.5, .1), 2)
sim = powerSim(m1, nsim = 100, test = fcompare(y ~ time))
sim
out1
dim(subset(out1, class == 'a'))
dim(subset(out1, class == 'a'))/4
subset(out1, class == 'a')
subset(out1, class == 'a' & time == 1)
dim(subset(out1, time == 1))
out1
k = subset(out1, time == 1)
count(k$treat)
68 * 3
200/3
### SIMPLE RANDOMIZATION
set.seed(888)
treatment <- c('A', 'B')
simple.list <- sample(treatment, 20, replace = TRUE)
cat(simple.list, sep = '\n')
table(simple.list)
library(blockrand)
set.seed(888)
block.list <- blockrand(n = 20, num.levels = 2, block.sizes = c(2, 2))
block.list
block.list2 <- blockrand(n = 20, num.levels = 2, block.sizes = c(1, 2))
block.list2
### STRATIFIED RANDOMIZATION
# Balance in patient characteristics may not be achieved in small studies
# Common strata: age, group, etc.
# Generate randomized list for each stratum
over50.severe.list <- blockrand(n = 100, num.levels = 2,
block.sizes = c(1, 2, 3, 4),
stratum = 'Over 50 Severe',
id.prefix = 'O50_S',
block.prefix = 'O50_S')
over50.severe.list
library(simr)
simr:::glmerSet
x1 = 'For Phase 1, our prime objective is to evaluate the STAR app from a pragmatic standpoint. That is, we are primarily concerned with usability and efficacy with respect to the perceptions of both patients and therapists. These assessments will be made based on qualitative reports from therapists, summarizing both their reactions to the STAR app feedback as well as perceived ease-of-use as reported by patients and therapists. We will also administer structured interviews and questionnaires to gauge the user experience with the app. The primary analyses for Phase 1 will, therefore, evaluate descriptive statistics and visualizations of responses to the CAT survey and self-report questionnaires to ensure proper functionality of the data-retrieval and collection procedures coordinated by PiLR mobile phone platform. No inferential testing will be performed during this stage, as our central goal is to ensure that the STAR app is functioning properly, does not introduce a substantial burden on patients, and produces usable and interpretable output for therapists. At the end of this stage, we will use the qualitative and quantitative feedback from therapists and patients to assess whether changes should be made to the STAR app, feedback-report protocol, or Unified Protocol modules.'
x2 = 'For Phase 1, our prime objective is to evaluate the STAR app from a pragmatic standpoint. That is, we are primarily concerned with usability and efficacy with respect to the perceptions of both patients and therapists. These assessments will be made based on qualitative reports from therapists, summarizing both their reactions to the STAR app feedback as well as perceived ease-of-use as reported by patients and therapists. We will also administer structured interviews and questionnaires to gauge the user experience with the app. The primary analyses for Phase 1 will, therefore, evaluate descriptive statistics and visualizations of responses to the CAT survey and self-report questionnaires to ensure proper functionality of the data-retrieval and collection procedures coordinated by PiLR mobile phone platform. No inferential testing will be performed during this stage, as our central goal is to ensure that the STAR app is functioning properly, does not introduce a substantial burden on patients, and produces usable and interpretable output for therapists. At the end of this stage, we will use the qualitative and quantitative feedback from therapists and patients to assess whether changes should be made to the STAR app, feedback-report protocol, or Unified Protocol modules.'
x1 == x2
x2 = 'This phase will consist of a pilot RCT of adolescent patients with AN who have been discharged from acute treatment to outpatient care. During this phase, patients will complete the computerized adaptive test (CAT) weekly within the STAR app over the course of 12 weeks. Additionally, therapists will report their patient’s height and weight so that we can calculate a standardized measure of body mass index (BMI-z) each week, which will serve as our primary outcome during this phase of the study. Based on the stratified permuted block randomization scheme (described in section D.3.1), at the beginning of the RCT patients (along with their therapists) will be randomized into one of three treatment groups based on recruitment site and level-of-care at discharge from acute treatment: 1) the STAR app only, without clinician feedback (STAR only), 2) the STAR app with clinician feedback (which will provide weekly risk-assessment predictions computed by a trained machine-learning algorithm [described in section C.2]) (STAR+feedback) and 3) the STAR app with clinician feedback and therapist and patient modules that provide evidence-based suggestions for both the patient and therapist (described in section D.2.2) (STAR+feedback+mHealth). Our central hypothesis is that patients randomized to STAR+feedback+mHealth will show significantly greater reductions in weight loss compared to conditions STAR only and STAR+feedback groups. In short, we expect that providing feedback and evidence-based mHealth modules to the patient and provider will be the core driver of the app’s utility.'
x1 = 'This phase will consist of a pilot RCT of adolescent patients with AN who have been discharged from acute treatment to outpatient care. During this phase, patients will complete the computerized adaptive test (CAT) weekly within the STAR app over the course of 12 weeks. Additionally, therapists will report their patient’s height and weight so that we can calculate a standardized measure of body mass index (BMI-z) each week, which will serve as our primary outcome during this phase of the study. Based on the stratified permuted block randomization scheme (described in section D.3.1), at the beginning of the RCT patients (along with their therapists) will be randomized into one of three treatment groups based on recruitment site and level-of-care at discharge from acute treatment: 1) the STAR app only, without clinician feedback (STAR only), 2) the STAR app with clinician feedback (which will provide weekly risk-assessment predictions computed by a trained machine-learning algorithm [described in section C.2]) (STAR+feedback) and 3) the STAR app with clinician feedback and therapist and patient modules that provide evidence-based suggestions for both the patient and therapist (described in section D.2.2) (STAR+feedback+mHealth). Our central hypothesis is that patients randomized to STAR+feedback+mHealth will show significantly greater reductions in weight loss compared to conditions STAR only and STAR+feedback groups. In short, we expect that providing feedback and evidence-based mHealth modules to the patient and provider will be the core driver of the app’s utility.'
x1 == x2
x1 = 'Our planned analysis for testing this hypothesis will be to use a linear mixed-effects model (LMM), wherein BMI-z is modeled at each timepoint (12, in total) as a function of the interaction between time and treatment condition. Given that our primary hypothesis is focused on the main (fixed) effects of treatment condition on differences in BMI-z, we conducted an a priori power analysis centered around these parameters in order to determine the necessary sample size for detecting the predicted effect. To estimate the power for this type of model, we constructed a power simulation in R using the simr package154, wherein we included random intercepts for individuals nested within three levels of severity (residential, PHP, IOP), as well as for the three clusters themselves. For this analysis we assumed a random intercept of 0.5 for individuals nested within clusters, a random intercept of 0.25 for the clusters, and a residual variance of 2. We do not include random slopes within this a priori analysis, because while we expect differences in the initial values of BMI-z across individuals and clusters, we do not expect usage of the app to affect these individuals differently over time. However, the importance of random slopes will be evaluated by fitting them on the data to determine their importance empirically. If models with random slopes outperform those with fixed slopes, we will then assess and report observed power to determine the reliability of the effects and inform future research.'
x2 = 'Our planned analysis for testing this hypothesis will be to use a linear mixed-effects model (LMM), wherein BMI-z is modeled at each timepoint (12, in total) as a function of the interaction between time and treatment condition. Given that our primary hypothesis is focused on the main (fixed) effects of treatment condition on differences in BMI-z, we conducted an a priori power analysis centered around these parameters in order to determine the necessary sample size for detecting the predicted effect. To estimate the power for this type of model, we constructed a power simulation in R using the simr package148, wherein we included random intercepts for individuals nested within three levels of severity (residential, PHP, IOP), as well as for the three clusters themselves. For this analysis we assumed a random intercept of 0.5 for individuals nested within clusters, a random intercept of 0.25 for the clusters, and a residual variance of 2. We do not include random slopes within this a priori analysis, because while we expect differences in the initial values of BMI-z across individuals and clusters, we do not expect usage of the app to affect these individuals differently over time. However, the importance of random slopes will be evaluated by fitting them on the data to determine their importance empirically. If models with random slopes outperform those with fixed slopes, we will then assess and report observed power to determine the reliability of the effects and inform future research.'
x1 == x2
x1
x = read.csv('~/Desktop/xxx.csv')
head(x)
which(x$last_name == 'Altman')
x[326, 1:5]
x = x[1:326, ]
dim(x)
34 * 10
340 - 14
x = read.csv('Desktop/xxx.csv')
which(x$last_name == 'Pinto')
400 - 18
which(x$last_name == 'Harvey')
500 - 21
which(x$last_name == 'Lloyd')
which(x$first_name == 'Darenique')
610 - 28
which(x$last_name == 'Thurman')
which(x$last_name == 'Thurman') + 31
dim(x)
which(x$last_name == 'Gordon')
setwd('Documents/memory-experiment/DATA/final')
dir()
file.edit('finalAnalysis.R')
source('extractData.R')
out <- getData(getJSONS(), matchPs = TRUE)
sorts <- lapply(out, lapply, getSorts)
inits <- data.frame(do.call(rbind, lapply(
lapply(out, lapply, getInits), function(z) data.frame(do.call(rbind, z)))
))
sorts$dat1 <- lapply(sorts$dat1, function(z){
z1 <- z[-(1:18), ]
z1$trial <- z1$trial - 2
return(z1)
})
simple <- lapply(sorts, function(z){
k <- seq(1, unique(sapply(z, nrow)), by = 9)
lapply(z, function(i) i[k, 1:3])
})
### Create datasets:
# Full data: all items, all IDs, all trials, all conditions
# Simple data: all IDs, all trials, all conditions
for(i in 1:3){
for(j in 1:length(sorts[[i]])){
sorts[[i]][[j]] <- cbind.data.frame(ID = j, sorts[[i]][[j]])
simple[[i]][[j]] <- cbind.data.frame(ID = j, simple[[i]][[j]])
}
sorts[[i]] <- data.frame(do.call(rbind, sorts[[i]]))
simple[[i]] <- data.frame(do.call(rbind, simple[[i]]))
}
sorts$dat2$trial <- sorts$dat2$trial + 30
simple$dat2$trial <- simple$dat2$trial + 30
sorts$dat3$trial <- sorts$dat3$trial + 60
simple$dat3$trial <- simple$dat3$trial + 60
for(i in 1:3){
sorts[[i]] <- data.frame(ID = sorts[[i]]$ID, session = i, sorts[[i]][, -1])
simple[[i]] <- data.frame(ID = simple[[i]]$ID, session = i, simple[[i]][, -1])
}
sorts <- data.frame(do.call(rbind, sorts))
simple <- data.frame(do.call(rbind, simple))
for(i in c('ID', 'session', 'condition')){
sorts[[i]] <- factor(sorts[[i]])
simple[[i]] <- factor(simple[[i]])
}
conditions <- c('SpaceSemTime', 'SpaceTime', 'SpaceSem', 'TimeSem', 'Control')
levels(sorts$condition) <- rev(levels(sorts$condition))
sorts$condition <- as.numeric(as.character(sorts$condition))
sorts$condition <- factor(sorts$condition)
levels(sorts$condition) <- rev(conditions)
levels(simple$condition) <- rev(levels(simple$condition))
simple$condition <- as.numeric(as.character(simple$condition))
simple$condition <- factor(simple$condition)
levels(simple$condition) <- rev(conditions)
sorts$correct <- sorts$correct/9
simple$correct <- simple$correct/9
rownames(sorts) <- 1:nrow(sorts)
rownames(simple) <- 1:nrow(simple)
sorts <- cbind(sorts, inits)
# write.csv(sorts, 'fullData.csv', row.names = FALSE)
# write.csv(simple, 'simpleData.csv', row.names = FALSE)
### ------------------------------------------------------------------------ ###
### ------------------------------- ANALYSES ------------------------------- ###
### ------------------------------------------------------------------------ ###
### Analysis 1: Simple dataset
if(!require(lme4)){install.packages('lme4', dependencies = TRUE)} # v1.1-19
if(!require(lsmeans)){install.packages('lsmeans', dependencies = TRUE)}
m0 <- lmer(correct ~ condition + (1|ID) + (1|session),
data = simple, REML = FALSE)
m1 <- lmer(correct ~ trial + (1|ID) + (1|session),
data = simple, REML = FALSE)
m2 <- lmer(correct ~ condition + trial + (1|ID) + (1|session),
data = simple, REML = FALSE)
m3 <- lmer(correct ~ condition * trial + (1|ID) + (1|session),
data = simple, REML = FALSE)
anova(m0, m2) # Is condition necessary, or only trial?
anova(m1, m2) # Is trial necessary, or only condition?
anova(m2, m3) # Are there interactions between trial and condition?
lsmeans(m2, pairwise ~ condition, adjust = 'tukey')
head(sorts)
dim(sorts)
head(sorts)
k = subset(sorts, ID == 1 & session == 1 & trial == 1)
k
grep('1$', colnames(k))
k[,grep('1$', colnames(k))]
apply(k[,grep('1$', colnames(k))], 1, function(z) paste0(z, collapse = ))
apply(k[,grep('1$', colnames(k))], 1, function(z) paste0(z, collapse = '.'))
head(sorts)
### Adapting Full Dataset
s1 <- apply(sorts[, grep('1$', colnames(sorts))], 1, function(z) paste0(z, collapse = '.'))
length(s1)
length(unique(sorts$trial))
56 * 9
count(sorts$trial)
56 * 9
### Adapting Full Dataset
ids <- split(sorts, sorts$ID)
length(ids)
ids$`1`
head(ids$`1`)
ids <- lapply(ids, function(z) split(z, z$trial))
ids$`1`$`1`
seq_along(ids)
i = 1
j = 1
ids[[1]][[1]]
k <- ids[[i]][[j]]
k
s1 <- apply(k[, grep('1$', colnames(k))], 1, function(zz) paste0(zz, collapse = '.'))
s1
s2 <- apply(k[, grep('0$', colnames(k))], 1, function(zz) paste0(zz, collapse = '.'))
s2
s1 %in% s2
s1 <- apply(k[, grep('1$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
s2 <- apply(k[, grep('0$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
s1
s2
s1 %in% s2
### Adapting Full Dataset
ids <- split(sorts, sorts$ID)
ids <- lapply(ids, function(z) split(z, z$trial))
for(i in seq_along(ids)){
for(j in seq_along(ids[[i]])){
k <- ids[[i]][[j]]
s1 <- apply(k[, grep('1$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
s2 <- apply(k[, grep('0$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
ids[[i]][[j]]$item_correct <- as.numeric(s1 %in% s2)
}
}
ids$`1`$`1`
ids$`1`$`2`
ids <- lapply(ids, function(z) data.frame(do.call(rbind, z)))
dim(ids$`1`)
head(ids$`1`)
### Adapting Full Dataset
ids <- split(sorts, sorts$ID)
ids <- lapply(ids, function(z) split(z, z$trial))
for(i in seq_along(ids)){
for(j in seq_along(ids[[i]])){
k <- ids[[i]][[j]]
s1 <- apply(k[, grep('1$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
s2 <- apply(k[, grep('0$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
ids[[i]][[j]]$item_correct <- as.numeric(s1 %in% s2)
}
}
ids <- data.frame(do.call(rbind, lapply(ids, function(z) data.frame(do.call(rbind, z)))))
head(ids)
row.names(ids) <- 1:nrow(ids)
head(ids)
dim(ids)
head(ids, 18)
### Adapting Full Dataset
ids <- split(sorts, sorts$ID)
ids <- lapply(ids, function(z) split(z, z$trial))
for(i in seq_along(ids)){
for(j in seq_along(ids[[i]])){
k <- ids[[i]][[j]]
s1 <- apply(k[, grep('1$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
s2 <- apply(k[, grep('0$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
ids[[i]][[j]]$item_correct <- as.numeric(s1 %in% s2)
ids[[i]][[j]]$time_correct <- as.numeric(s1 == s2)
}
}
ids <- data.frame(do.call(rbind, lapply(ids, function(z) data.frame(do.call(rbind, z)))))
row.names(ids) <- 1:nrow(ids)
count(ids$time_correct)
head(ids)
kk = ids[which(ids$time_correct == 1), ]
head(kk)
head(sorts)
### Adapting Full Dataset
ids <- split(sorts, sorts$ID)
ids <- lapply(ids, function(z) split(z, z$trial))
ids$`1`$`1`
dir()
dir()
head(sorts)
head(simple)
count(simple$correct)
### PLOTS
sess <- lapply(1:3, function(z) subset(simple, session == z))
head(sess$)
head(sess[[1]])
par(mfrow = c(2, 2))
for(i in 1:3){hist(sess[[i]]$correct, main = '', xlab = paste('Session', i))}
head(simple)
idcorr <- split(simple, simple$ID)
idcorr$`1`
idcorr <- lapply(split(simple, simple$ID), '[[', 'correct')
idcorr$`1`
sum(idcorr$`1`)
mean(idcorr$`1`)
idcorr <- sapply(lapply(split(simple, simple$ID), '[[', 'correct'), mean)
idcorr
plot(sort(idcorr))
dev.off()
sess <- lapply(1:3, function(z) subset(simple, session == z))
par(mfrow = c(2, 2))
for(i in 1:3){hist(sess[[i]]$correct, main = '', xlab = paste('Session', i))}
idcorr <- sapply(lapply(split(simple, simple$ID), '[[', 'correct'), mean)
plot(sort(idcorr), type = 'b', ylab = 'Average Overall Performance')
sess <- lapply(1:3, function(z) subset(simple, session == z))
par(mfrow = c(2, 2))
for(i in 1:3){hist(sess[[i]]$correct, main = '', xlab = paste('Session', i))}
idcorr <- sapply(lapply(split(simple, simple$ID), '[[', 'correct'), mean)
plot(sort(idcorr), type = 'b', ylab = 'Average Overall Performance', xlab = '')
head(sorts)
### Coding Errors
ids <- split(sorts, sorts$ID)
ids <- lapply(ids, function(z) split(z, z$trial))
for(i in seq_along(ids)){
for(j in seq_along(ids[[i]])){
k <- ids[[i]][[j]]
s1 <- apply(k[, grep('1$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
s2 <- apply(k[, grep('0$', colnames(k))[1:4]], 1, function(zz) paste0(zz, collapse = '.'))
s3 <- apply(k[, c('cat1', 'src1', 'room1')], 1, function(zz) paste0(zz, collapse = '.'))
s4 <- apply(k[, c('cat0', 'src0', 'room0')], 1, function(zz) paste0(zz, collapse = '.'))
s5 <- apply(k[, c('cat1', 'loc1')], 1, function(zz) paste0(zz, collapse = '.'))
s6 <- apply(k[, c('cat0', 'loc0')], 1, function(zz) paste0(zz, collapse = '.'))
ids[[i]][[j]]$item_correct <- as.numeric(s1 %in% s2)
ids[[i]][[j]]$time_correct <- as.numeric(s1 == s2)
ids[[i]][[j]]$room_correct <- as.numeric(s3 %in% s4)
ids[[i]][[j]]$cat_correct <- as.numeric(s5 %in% s6)
}
}
ids <- data.frame(do.call(rbind, lapply(ids, function(z) data.frame(do.call(rbind, z)))))
row.names(ids) <- 1:nrow(ids)
head(ids)
count(ids$cat_correct)
count(ids$room_correct)
head(ids)
head(simple)
### ------------------------------------------------------------------------ ###
### --------------------------- DATA PREPARATION --------------------------- ###
### ------------------------------------------------------------------------ ###
if(!require(ggplot2)){install.packages('ggplot2', dependencies = TRUE)}
ggplot(simple, aes(x = trial, y = correct, color = factor(ID))) +
geom_line() + geom_point() + theme_bw()
modnets()
file.edit('plots.R')
file.edit('ggm.R')
head(simple)
setwd("~/Documents/memory-experiment/DATA/final")
